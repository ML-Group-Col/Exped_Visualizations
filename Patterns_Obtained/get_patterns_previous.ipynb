{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f515a261c91f2d540a32fd338636eea76c71c483334d8e72b3eaaa34365c9198"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Pbc4cip- Python Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import weka.core.jvm as jvm\n",
    "import weka.core.packages as packages\n",
    "from weka.core.classes import complete_classname\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Classifier\n",
    "import weka.plot.graph as graph  # NB: pygraphviz and PIL are required\n",
    "from weka.core.classes import Random, from_commandline\n",
    "import weka.core.serialization as serialization\n",
    "from weka.filters import Filter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Michael\n",
    "#wekafiles_path = \"C:/Users/mzenk/wekafiles\"\n",
    "#PBC4CIP_zip_path = \"C:/Users/mzenk/Google Drive/ITESM/Maestría/Semestre 3/ML2/Assignment4/PBC4cip-1.0-weka.zip\"\n",
    "#data_dir = \"C:/Users/mzenk/Google Drive/ITESM/Maestría/Semestre 3/ML2/Assignment4/Exped_Visualizations/\"\n",
    "#arff_file = \"weka_dataset_clean_noop_nocorreo.arff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dany\n",
    "wekafiles_path = \"/Users/dannygc/wekafiles\"\n",
    "PBC4CIP_zip_path = \"/Users/dannygc/Google Drive File Stream/My Drive/MCCNotes/MCC 3/Adv_ML/PBC_HW4/PBC4cip-1.0-weka.zip\"\n",
    "data_dir = \"/Volumes/GoogleDrive/My Drive/MCCNotes/Jlab projects/GITHUB_repositories/DRAE_repositories/Exped_Visualizations/\"\n",
    "arff_file = \"weka_dataset_clean_.arff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Constraints\n",
    "updated_PBC4CIP = False\n",
    "min_support_diff = 0.3\n",
    "min_count_diff = 30\n",
    "min_ratio = 0.6\n",
    "max_patterns = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "trees = 150\n",
    "maxDepth = 5\n",
    "min_objectsByLeaf = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attname = 'Forma del procedimiento'\n",
    "attnum = 0\n",
    "filename = attname + str(attnum)\n",
    "\n",
    "# Dictionary with the nominal attributes in order, and their respective onehot indexes\n",
    "# Only change this if an attribute is moved or deleted\n",
    "\"\"\" nom_pos = {\n",
    "    'Caracter del procedimiento' : [18,19],\n",
    "    'Forma del procedimiento' : [7,8,9],\n",
    "    'Operador' : [],\n",
    "    'Correo electronico' : [],\n",
    "    'Entidad federativa' : [10,11,12,13,14,15],\n",
    "    'Tipo de contratación' : [21,22,23,24,25],\n",
    "    'Articulo' : [18,19,20],\n",
    "    'Plantilla' : [26,27,28,29,30,31]\n",
    "} \"\"\"\n",
    "nom_pos = {\n",
    "    'Caracter del procedimiento' : [18,19],\n",
    "    'Forma del procedimiento' : [9,10,11],\n",
    "    'Operador' : [],\n",
    "    'Correo electronico' : [],\n",
    "    'Entidad federativa' : [12,13,14,15,16,17],\n",
    "    'Tipo de contratación' : [23,24,25,26,27],\n",
    "    'Articulo' : [20,22,22],\n",
    "    'Plantilla' : [28,29,30,31,32,33]\n",
    "}\n",
    "class_index = len(nom_pos.keys()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "len(nom_pos.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{&#39;Caracter del procedimiento&#39;: [18, 19],\n &#39;Forma del procedimiento&#39;: [9, 10, 11],\n &#39;Operador&#39;: [],\n &#39;Correo electronico&#39;: [],\n &#39;Entidad federativa&#39;: [12, 13, 14, 15, 16, 17],\n &#39;Tipo de contratación&#39;: [23, 24, 25, 26, 27],\n &#39;Articulo&#39;: [20, 22, 22],\n &#39;Plantilla&#39;: [28, 29, 30, 31, 32, 33]}"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "nom_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = 'dany.pickle'\n",
    "load_pickle = True\n",
    "save_pickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_pickle:\n",
    "    with open(pickle_file, 'wb') as f:\n",
    "        pickle.dump([   wekafiles_path,\n",
    "                        PBC4CIP_zip_path,\n",
    "                        data_dir,\n",
    "                        arff_file,\n",
    "                        updated_PBC4CIP], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_pickle:\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        wekafiles_path, PBC4CIP_zip_path, data_dir, arff_file, updated_PBC4CIP = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "DEBUG:weka.core.jvm:Adding bundled jars\nDEBUG:weka.core.jvm:Classpath=[&#39;/Users/dannygc/anaconda3/lib/python3.7/site-packages/javabridge/jars/rhino-1.7R4.jar&#39;, &#39;/Users/dannygc/anaconda3/lib/python3.7/site-packages/javabridge/jars/runnablequeue.jar&#39;, &#39;/Users/dannygc/anaconda3/lib/python3.7/site-packages/javabridge/jars/cpython.jar&#39;, &#39;/Users/dannygc/anaconda3/lib/python3.7/site-packages/weka/lib/python-weka-wrapper.jar&#39;, &#39;/Users/dannygc/anaconda3/lib/python3.7/site-packages/weka/lib/weka.jar&#39;]\nDEBUG:weka.core.jvm:MaxHeapSize=12g\nDEBUG:weka.core.jvm:Using alternative Weka home directory: /Users/dannygc/wekafiles\nDEBUG:weka.core.jvm:Using alternative Weka home directory: /Users/dannygc/wekafiles\n"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#jvm.start(packages=True, max_heap_size=\"12g\") #max_heap_size 512m, 4g. packages=true searches for weka packages in installation program\n",
    "jvm.start(packages=wekafiles_path, max_heap_size='12g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "weka.classifiers.trees.PBC4cip\nPBC4cip is already installed.\n"
    }
   ],
   "source": [
    "pkg = \"PBC4cip\"\n",
    "print(complete_classname(\".\" + pkg))\n",
    "# install package if necessary \n",
    "if not packages.is_installed(pkg):\n",
    "    print(\"Installing %s...\" % pkg)\n",
    "    #packages.install_package(\"http://prdownloads.sourceforge.net/weka/discriminantAnalysis1.0.3.zip?download\")\n",
    "    packages.install_package(PBC4CIP_zip_path)\n",
    "    print(\"Installed %s, please re-run script!\" % pkg)\n",
    "    jvm.stop()\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    print(pkg + \" is already installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n\n\n\n\n&gt;&gt;&gt; Start...\n"
    }
   ],
   "source": [
    "# testing classname completion\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(\">>> Start...\")\n",
    "\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "data = loader.load_file(data_dir + arff_file)\n",
    "\n",
    "cmdline = []"
   ]
  },
  {
   "source": [
    "# Preprocess\n",
    "Here the one-hot attributes not used are deleted.\n",
    "Also the nominal attribute where the class being evaluated comes from is also deleted."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;Caracter del procedimiento&#39;,\n &#39;Forma del procedimiento&#39;,\n &#39;Operador&#39;,\n &#39;Correo electronico&#39;,\n &#39;Entidad federativa&#39;,\n &#39;Tipo de contratacion&#39;,\n &#39;Articulo&#39;,\n &#39;Plantilla&#39;,\n &#39;Forma_Procedimiento_Presencial&#39;,\n &#39;Forma_Procedimiento_Electronica&#39;,\n &#39;Forma_Procedimiento_Mixta&#39;,\n &#39;Entidad_federativa_Norte&#39;,\n &#39;Entidad_federativa_Centro&#39;,\n &#39;Entidad_federativa_Golfo&#39;,\n &#39;Entidad_federativa_PacificoSur&#39;,\n &#39;Entidad_federativa_Sur&#39;,\n &#39;Entidad_federativa_PacificoNorte&#39;,\n &#39;Caracter del procedimiento_Nacional&#39;,\n &#39;Caracter del procedimiento_Internacional&#39;,\n &#39;Articulo de excepcion_41&#39;,\n &#39;Articulo de excepcion_42&#39;,\n &#39;Articulo de excepcion_43&#39;,\n &#39;Contratacion_adquisiciones&#39;,\n &#39;Contratacion_servicios&#39;,\n &#39;Contratacion_obra_publica&#39;,\n &#39;Contratacion_arrendamientos&#39;,\n &#39;Contratacion_servicios_op&#39;,\n &#39;Plantilla_Proyecto&#39;,\n &#39;Plantilla_Adjudicación&#39;,\n &#39;Plantilla_Licitación&#39;,\n &#39;Plantilla_Invitación&#39;,\n &#39;Plantilla_Reporte&#39;,\n &#39;Plantilla_Contratos&#39;,\n &#39;Most_used_description_word_servici&#39;,\n &#39;Most_used_description_word_adquisicion&#39;,\n &#39;Most_used_description_word_material&#39;,\n &#39;Mes_pub&#39;,\n &#39;Dia_pub&#39;,\n &#39;Hora_pub&#39;,\n &#39;Most_used_UC_word_gyr&#39;,\n &#39;Most_used_UC_word_material&#39;,\n &#39;Most_used_UC_word_general&#39;]"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "attributes = [f.name for f in data.attributes()]\n",
    "attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_vector = [False for i in range(len(attributes))]\n",
    "pos_vector[0:len(nom_pos.keys())] = [True for i in range(len(nom_pos.keys()))]\n",
    "pos_vector[len(attributes)-9:len(attributes)] = [True for i in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[True,\n True,\n True,\n True,\n True,\n True,\n True,\n True,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n False,\n True,\n True,\n True,\n True,\n True,\n True,\n True,\n True,\n True]"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "pos_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Dict that will contain filtered datasets\n",
    "filtered_data = {\n",
    "    'Caracter del procedimiento' : [],\n",
    "    'Forma del procedimiento' : [],\n",
    "    'Entidad federativa' : [],\n",
    "    'Tipo de contratación' : [],\n",
    "    'Articulo' : [],\n",
    "    'Plantilla' : []\n",
    "}\n",
    "for key, value in nom_pos.items():\n",
    "    for onehot_att in value:\n",
    "        # Here modify pos vector then feed it into weka remove\n",
    "        # Change nom att to false\n",
    "        # Change only specific onehot to true\n",
    "        # See how to save it to change the class also\n",
    "        nominal_att_index = list(nom_pos.keys()).index(key)\n",
    "        pos_vector[nominal_att_index] = False\n",
    "        pos_vector[onehot_att-1] = True\n",
    "        indeces_not_filtered = [i+1 for i, val in enumerate(pos_vector) if val]\n",
    "        pos_vector[nominal_att_index] = True\n",
    "        pos_vector[onehot_att-1] = False\n",
    "        remove = Filter(classname=\"weka.filters.unsupervised.attribute.Remove\", options=[\"-R\",\",\".join(map(str, indeces_not_filtered)),\"-V\"])\n",
    "        remove.inputformat(data)\n",
    "        filtered_data[key].append(remove.filter(data))\n",
    "            "
   ]
  },
  {
   "source": [
    "# Criterions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = filtered_data[attname][attnum]\n",
    "data.class_index = class_index\n",
    "\n",
    "print(\"Class attribute is: \" + [f.name for f in data.attributes()][class_index])\n",
    "print(f'Max Depth is: {maxDepth}')\n",
    "print(f'Number of Trees is: {trees}')\n",
    "print(f'Min Objects by Leaf is: {min_objectsByLeaf}')\n",
    "\n",
    "input_config = f'weka.classifiers.trees.PBC4cip -S 1 -miner \\\"PRFramework.Core.SupervisedClassifiers.EmergingPatterns.Miners.RandomForestMinerWithFiltering -bagSizePercent 100 -numFeatures -1 -numTrees {trees} -builder \\\\\\\"PRFramework.Core.SupervisedClassifiers.DecisionTrees.Builder.DecisionTreeBuilder -distributionEvaluator \\\\\\\\\\\\\\\"PRFramework.Core.SupervisedClassifiers.DecisionTrees.DistributionEvaluators.Hellinger \\\\\\\\\\\\\\\" -maxDepth {maxDepth} \\\\\\\\\\\\\\\"-minimalObjByLeaf \\\\\\\\\\\\\\\" {min_objectsByLeaf} -minimalSplitGain 1.0E-30\\\\\\\"\\\"'\n",
    "\n",
    "\n",
    "#weka.classifiers.trees.PBC4cip -S 1 -miner \"PRFramework.Core.SupervisedClassifiers.EmergingPatterns.Miners.RandomForestMinerWithoutFiltering -bagSizePercent 100 -numFeatures -1 -numTrees 150 -builder \\\"PRFramework.Core.SupervisedClassifiers.DecisionTrees.Builder.DecisionTreeBuilder -distributionEvaluator \\\\\\\"PRFramework.Core.SupervisedClassifiers.DecisionTrees.DistributionEvaluators.Hellinger \\\\\\\" -maxDepth 5 \\\\\\\"-minimalObjByLeaf \\\\\\\" 35 -minimalSplitGain 1.0E-30\\\"\"\n",
    "\n",
    "\n",
    "classifier = from_commandline(input_config, classname=\"weka.classifiers.Classifier\")\n",
    "\n",
    "print(\">>> Building classifier...\")\n",
    "start_time_1 = time.time()\n",
    "classifier.build_classifier(data)\n",
    "print(f\">>> [Done] Bulding classifier. Time: {(time.time() - start_time_1)} seconds ---\")\n",
    "\n",
    "print(\">>> Serializing model...\")\n",
    "start_time_1 = time.time()\n",
    "classifier.serialize(f\"{filename}.model\")\n",
    "print(f\">>> [Done] Serializing model. Time: {(time.time() - start_time_1)} seconds ---\")\n",
    "\n",
    "print(\">>> Generating big string...\")\n",
    "start_time_1 = time.time()\n",
    "big_string = str(classifier).split(\"]\\n\")\n",
    "print(f\">>> [Done] Generating big string. Time: {(time.time() - start_time_1)} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c0_count:  48999\nc1_count:  47123\nTotal:  96122\n"
    }
   ],
   "source": [
    "c0_count = 0\n",
    "c1_count = 0\n",
    "\n",
    "for instance in data:\n",
    "    if instance.values[class_index] == 0:\n",
    "        c0_count += 1\n",
    "    else:\n",
    "        c1_count += 1\n",
    "print('c0_count: ', c0_count)\n",
    "print('c1_count: ', c1_count)\n",
    "print('Total: ', c0_count + c1_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 2094/2094 [00:00&lt;00:00, 75226.74it/s]\n"
    }
   ],
   "source": [
    "list_fields = []\n",
    "list_support_c0 = []\n",
    "list_support_c1 = []\n",
    "list_num_c0 = []\n",
    "list_num_c1 = []\n",
    "list_diff = []\n",
    "with tqdm(total=len(big_string)) as pbar:\n",
    "    for item in big_string:\n",
    "        text = \"\"\n",
    "        text = item + \"]\"\n",
    "        text = text.split(\"[\")\n",
    "        fields = text[0]\n",
    "        # print(fields)\n",
    "        if updated_PBC4CIP:\n",
    "            if (len(text) > 1):\n",
    "                class_nums = text[1]\n",
    "                class_nums = class_nums[:-1]\n",
    "                class_nums = class_nums.split()\n",
    "                supports = text[2]\n",
    "                supports = supports[:-1]\n",
    "                supports = supports.split()\n",
    "                list_fields.append(fields.strip())\n",
    "                list_support_c0.append(float(supports[0]))\n",
    "                list_support_c1.append(float(supports[1]))\n",
    "                list_num_c0.append(float(class_nums[0]))\n",
    "                list_num_c1.append(float(class_nums[1]))\n",
    "        else:\n",
    "            if (len(text) > 1):\n",
    "                supports = text[1]\n",
    "                supports = supports[:-1]\n",
    "                supports = supports.split()\n",
    "                list_fields.append(fields.strip())\n",
    "                list_support_c0.append(float(supports[0]))\n",
    "                list_support_c1.append(float(supports[1]))\n",
    "                list_num_c0.append(float(supports[0])*c0_count)\n",
    "                list_num_c1.append(float(supports[1])*c1_count)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               patterns  support_c0  \\\n2088  Operador != &#39;irma olga arredondo murillo&#39; AND ...        0.72   \n2089  Caracter del procedimiento = &#39;nacional&#39; AND Pl...        0.54   \n2090  Caracter del procedimiento = &#39;nacional&#39; AND Mo...        0.41   \n2091  Plantilla != &#39;proyecto&#39; AND Operador != &#39;irma ...        0.83   \n2092  Caracter del procedimiento = &#39;nacional&#39; AND Mo...        0.56   \n\n      support_c1    num_c0    num_c1  \n2088        0.60  35279.28  28273.80  \n2089        0.80  26459.46  37698.40  \n2090        0.81  20089.59  38169.63  \n2091        0.49  40669.17  23090.27  \n2092        0.89  27439.44  41939.47  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patterns</th>\n      <th>support_c0</th>\n      <th>support_c1</th>\n      <th>num_c0</th>\n      <th>num_c1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2088</th>\n      <td>Operador != 'irma olga arredondo murillo' AND ...</td>\n      <td>0.72</td>\n      <td>0.60</td>\n      <td>35279.28</td>\n      <td>28273.80</td>\n    </tr>\n    <tr>\n      <th>2089</th>\n      <td>Caracter del procedimiento = 'nacional' AND Pl...</td>\n      <td>0.54</td>\n      <td>0.80</td>\n      <td>26459.46</td>\n      <td>37698.40</td>\n    </tr>\n    <tr>\n      <th>2090</th>\n      <td>Caracter del procedimiento = 'nacional' AND Mo...</td>\n      <td>0.41</td>\n      <td>0.81</td>\n      <td>20089.59</td>\n      <td>38169.63</td>\n    </tr>\n    <tr>\n      <th>2091</th>\n      <td>Plantilla != 'proyecto' AND Operador != 'irma ...</td>\n      <td>0.83</td>\n      <td>0.49</td>\n      <td>40669.17</td>\n      <td>23090.27</td>\n    </tr>\n    <tr>\n      <th>2092</th>\n      <td>Caracter del procedimiento = 'nacional' AND Mo...</td>\n      <td>0.56</td>\n      <td>0.89</td>\n      <td>27439.44</td>\n      <td>41939.47</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['patterns', 'support_c0', 'support_c1', 'num_c0', 'num_c1'])\n",
    "df['patterns']=list_fields\n",
    "df['support_c0']=list_support_c0\n",
    "df['support_c1']= list_support_c1\n",
    "df['num_c0']= list_num_c0\n",
    "df['num_c1']= list_num_c1\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                               patterns  support_c0  \\\n2081  Most_used_UC_word_gyr = &#39;0&#39; AND Caracter del p...        0.18   \n2080  Caracter del procedimiento = &#39;nacional&#39; AND Ar...        0.18   \n2075  Articulo != &#39;42&#39; AND Caracter del procedimient...        0.18   \n2066  Most_used_UC_word_gyr = &#39;0&#39; AND Plantilla = &#39;a...        0.16   \n2065  Most_used_UC_word_gyr = &#39;0&#39; AND Plantilla = &#39;a...        0.16   \n\n      support_c1   num_c0    num_c1  s_diff    n_diff     ratio  \n2081        0.68  8819.82  32043.64    0.50  23223.82  0.784164  \n2080        0.68  8819.82  32043.64    0.50  23223.82  0.784164  \n2075        0.66  8819.82  31101.18    0.48  22281.36  0.779068  \n2066        0.64  7839.84  30158.72    0.48  22318.88  0.793681  \n2065        0.64  7839.84  30158.72    0.48  22318.88  0.793681  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>patterns</th>\n      <th>support_c0</th>\n      <th>support_c1</th>\n      <th>num_c0</th>\n      <th>num_c1</th>\n      <th>s_diff</th>\n      <th>n_diff</th>\n      <th>ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2081</th>\n      <td>Most_used_UC_word_gyr = '0' AND Caracter del p...</td>\n      <td>0.18</td>\n      <td>0.68</td>\n      <td>8819.82</td>\n      <td>32043.64</td>\n      <td>0.50</td>\n      <td>23223.82</td>\n      <td>0.784164</td>\n    </tr>\n    <tr>\n      <th>2080</th>\n      <td>Caracter del procedimiento = 'nacional' AND Ar...</td>\n      <td>0.18</td>\n      <td>0.68</td>\n      <td>8819.82</td>\n      <td>32043.64</td>\n      <td>0.50</td>\n      <td>23223.82</td>\n      <td>0.784164</td>\n    </tr>\n    <tr>\n      <th>2075</th>\n      <td>Articulo != '42' AND Caracter del procedimient...</td>\n      <td>0.18</td>\n      <td>0.66</td>\n      <td>8819.82</td>\n      <td>31101.18</td>\n      <td>0.48</td>\n      <td>22281.36</td>\n      <td>0.779068</td>\n    </tr>\n    <tr>\n      <th>2066</th>\n      <td>Most_used_UC_word_gyr = '0' AND Plantilla = 'a...</td>\n      <td>0.16</td>\n      <td>0.64</td>\n      <td>7839.84</td>\n      <td>30158.72</td>\n      <td>0.48</td>\n      <td>22318.88</td>\n      <td>0.793681</td>\n    </tr>\n    <tr>\n      <th>2065</th>\n      <td>Most_used_UC_word_gyr = '0' AND Plantilla = 'a...</td>\n      <td>0.16</td>\n      <td>0.64</td>\n      <td>7839.84</td>\n      <td>30158.72</td>\n      <td>0.48</td>\n      <td>22318.88</td>\n      <td>0.793681</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "df['s_diff'] = df.support_c1 - df.support_c0\n",
    "df['n_diff'] = df.num_c1 - df.num_c0\n",
    "df['ratio'] = df.num_c1/(df.num_c0 + df.num_c1)\n",
    "\n",
    "df = df[df.s_diff > min_support_diff]\n",
    "df = df[df.n_diff > min_count_diff]\n",
    "df = df[df.ratio > min_ratio]\n",
    "\n",
    "df = df.sort_values(by=['s_diff'], ascending=False)\n",
    "df = df[:max_patterns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## Export to Patterns Obtained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"Patterns_Obtained/{filename}.csv\", index=False)\n",
    "jvm.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}