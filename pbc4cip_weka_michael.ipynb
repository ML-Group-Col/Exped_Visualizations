{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f515a261c91f2d540a32fd338636eea76c71c483334d8e72b3eaaa34365c9198"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import weka.core.jvm as jvm\n",
    "import weka.core.packages as packages\n",
    "from weka.core.classes import complete_classname\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Classifier\n",
    "import weka.plot.graph as graph  # NB: pygraphviz and PIL are required\n",
    "from weka.core.classes import Random, from_commandline\n",
    "import weka.core.serialization as serialization\n",
    "from weka.filters import Filter\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wekafiles_path = \"C:/Users/mzenk/wekafiles\"\n",
    "PBC4CIP_zip_path = \"C:/Users/mzenk/Google Drive/ITESM/Maestría/Semestre 3/ML2/Assignment4/PBC4cip-1.0-weka.zip\"\n",
    "data_dir = \"C:/Users/mzenk/Google Drive/ITESM/Maestría/Semestre 3/ML2/Assignment4/Exped_Visualizations/\"\n",
    "arff_file = \"weka_dataset_clean_.arff\"\n",
    "updated_PBC4CIP = True\n",
    "min_support_diff = 0.3\n",
    "min_count_diff = 30\n",
    "min_ratio = 0.6\n",
    "max_patterns = 15\n",
    "\n",
    "attname = 'Caracter del procedimiento'\n",
    "attnum = 0\n",
    "filename = attname + str(attnum)\n",
    "\n",
    "trees = 150\n",
    "maxDepth = 10\n",
    "objectsByLeaf = 35\n",
    "\n",
    "# Dictionary with the nominal attributes in order, and their respective onehot indexes\n",
    "# Only change this if an attribute is moved or deleted\n",
    "nom_pos = {\n",
    "    'Caracter del procedimiento' : [18,19],\n",
    "    'Forma del procedimiento' : [7,8,9],\n",
    "    'Operador' : [],\n",
    "    'Correo electronico' : [],\n",
    "    'Entidad federativa' : [10,11,12,13,14,15],\n",
    "    'Tipo de contratación' : [21,22,23,24,25],\n",
    "    'Articulo' : [18,19,20],\n",
    "    'Plantilla' : [26,27,28,29,30,31]\n",
    "}\n",
    "class_index = len(nom_pos.keys())-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "DEBUG:weka.core.jvm:Adding bundled jars\nDEBUG:weka.core.jvm:Classpath=[&#39;C:\\\\Users\\\\mzenk\\\\anaconda3\\\\lib\\\\site-packages\\\\javabridge-1.0.18-py3.7-win-amd64.egg\\\\javabridge\\\\jars\\\\rhino-1.7R4.jar&#39;, &#39;C:\\\\Users\\\\mzenk\\\\anaconda3\\\\lib\\\\site-packages\\\\javabridge-1.0.18-py3.7-win-amd64.egg\\\\javabridge\\\\jars\\\\runnablequeue.jar&#39;, &#39;C:\\\\Users\\\\mzenk\\\\anaconda3\\\\lib\\\\site-packages\\\\javabridge-1.0.18-py3.7-win-amd64.egg\\\\javabridge\\\\jars\\\\cpython.jar&#39;, &#39;C:\\\\Users\\\\mzenk\\\\anaconda3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\python-weka-wrapper.jar&#39;, &#39;C:\\\\Users\\\\mzenk\\\\anaconda3\\\\lib\\\\site-packages\\\\weka\\\\lib\\\\weka.jar&#39;]\nDEBUG:weka.core.jvm:MaxHeapSize=12g\nDEBUG:weka.core.jvm:Using alternative Weka home directory: C:/Users/mzenk/wekafiles\nDEBUG:weka.core.jvm:Using alternative Weka home directory: C:/Users/mzenk/wekafiles\n"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#jvm.start(packages=True, max_heap_size=\"12g\") #max_heap_size 512m, 4g. packages=true searches for weka packages in installation program\n",
    "jvm.start(packages=wekafiles_path, max_heap_size='12g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "weka.classifiers.trees.PBC4cip\nPBC4cip is already installed.\n"
    }
   ],
   "source": [
    "pkg = \"PBC4cip\"\n",
    "print(complete_classname(\".\" + pkg))\n",
    "# install package if necessary \n",
    "if not packages.is_installed(pkg):\n",
    "    print(\"Installing %s...\" % pkg)\n",
    "    #packages.install_package(\"http://prdownloads.sourceforge.net/weka/discriminantAnalysis1.0.3.zip?download\")\n",
    "    packages.install_package(PBC4CIP_zip_path)\n",
    "    print(\"Installed %s, please re-run script!\" % pkg)\n",
    "    jvm.stop()\n",
    "    sys.exit(0)\n",
    "else:\n",
    "    print(pkg + \" is already installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n\n\n\n\n\n&gt;&gt;&gt; Start...\n"
    }
   ],
   "source": [
    "# testing classname completion\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(\">>> Start...\")\n",
    "\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "data = loader.load_file(data_dir + arff_file)\n",
    "\n",
    "cmdline = []"
   ]
  },
  {
   "source": [
    "# Preprocess\n",
    "Here the one-hot attributes not used are deleted.\n",
    "Also the nominal attribute where the class being evaluated comes from is also deleted."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_vector = [False for i in range(43)]\n",
    "pos_vector[0:8] = [True for i in range(8)]\n",
    "pos_vector[33:43] = [True for i in range(10)]\n",
    "\n",
    "# Dict that will contain filtered datasets\n",
    "filtered_data = {\n",
    "    'Caracter del procedimiento' : [],\n",
    "    'Forma del procedimiento' : [],\n",
    "    'Entidad federativa' : [],\n",
    "    'Tipo de contratación' : [],\n",
    "    'Articulo' : [],\n",
    "    'Plantilla' : []\n",
    "}\n",
    "for key, value in nom_pos.items():\n",
    "    for onehot_att in value:\n",
    "        # Here modify pos vector then feed it into weka remove\n",
    "        # Change nom att to false\n",
    "        # Change only specific onehot to true\n",
    "        # See how to save it to change the class also\n",
    "        nominal_att_index = list(nom_pos.keys()).index(key)\n",
    "        pos_vector[nominal_att_index] = False\n",
    "        pos_vector[onehot_att-1] = True\n",
    "        indeces_not_filtered = [i+1 for i, val in enumerate(pos_vector) if val]\n",
    "        pos_vector[nominal_att_index] = True\n",
    "        pos_vector[onehot_att-1] = False\n",
    "        remove = Filter(classname=\"weka.filters.unsupervised.attribute.Remove\", options=[\"-R\",\",\".join(map(str, indeces_not_filtered)),\"-V\"])\n",
    "        remove.inputformat(data)\n",
    "        filtered_data[key].append(remove.filter(data))\n",
    "            "
   ]
  },
  {
   "source": [
    "# Criterions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "&gt;&gt;&gt; Building classifier...\n&gt;&gt;&gt; [Done] Bulding classifier. Time: 291.99608278274536 seconds ---\n&gt;&gt;&gt; Serializing model...\n&gt;&gt;&gt; [Done] Serializing model. Time: 0.3091411590576172 seconds ---\n&gt;&gt;&gt; Generating big string...\n&gt;&gt;&gt; [Done] Generating big string. Time: 54.8722722530365 seconds ---\n"
    }
   ],
   "source": [
    "data = filtered_data[attname][attnum]\n",
    "data.class_index = class_index\n",
    "\n",
    "input_config = f'weka.classifiers.trees.PBC4cip -S 1 -miner \\\"PRFramework.Core.SupervisedClassifiers.EmergingPatterns.Miners.RandomForestMinerWithoutFiltering -bagSizePercent 100 -numFeatures -1 -numTrees {trees} -builder \\\\\\\"PRFramework.Core.SupervisedClassifiers.DecisionTrees.Builder.DecisionTreeBuilder -distributionEvaluator \\\\\\\\\\\\\\\"PRFramework.Core.SupervisedClassifiers.DecisionTrees.DistributionEvaluators.QuinlanGain \\\\\\\\\\\\\\\" -maxDepth {maxDepth} \\\\\\\\\\\\\\\"-minimalObjByLeaf \\\\\\\\\\\\\\\" {objectsByLeaf} -minimalSplitGain 1.0E-30\\\\\\\"\\\"'\n",
    "\n",
    "classifier = from_commandline(input_config, classname=\"weka.classifiers.Classifier\")\n",
    "\n",
    "print(\">>> Building classifier...\")\n",
    "start_time_1 = time.time()\n",
    "classifier.build_classifier(data)\n",
    "print(f\">>> [Done] Bulding classifier. Time: {(time.time() - start_time_1)} seconds ---\")\n",
    "\n",
    "print(\">>> Serializing model...\")\n",
    "start_time_1 = time.time()\n",
    "classifier.serialize(f\"{filename}.model\")\n",
    "print(f\">>> [Done] Serializing model. Time: {(time.time() - start_time_1)} seconds ---\")\n",
    "\n",
    "print(\">>> Generating big string...\")\n",
    "start_time_1 = time.time()\n",
    "big_string = str(classifier).split(\"]\\n\")\n",
    "print(f\">>> [Done] Generating big string. Time: {(time.time() - start_time_1)} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "96122\n"
    }
   ],
   "source": [
    "attributes = []\n",
    "\n",
    "c0_count = 0\n",
    "c1_count = 0\n",
    "\n",
    "for instance in data:\n",
    "    if instance.values[class_index] == 0:\n",
    "        c0_count += 1\n",
    "    else:\n",
    "        c1_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "100%|██████████| 19681/19681 [00:00&lt;00:00, 256279.37it/s]\n"
    }
   ],
   "source": [
    "list_fields = []\n",
    "list_support_c0 = []\n",
    "list_support_c1 = []\n",
    "list_num_c0 = []\n",
    "list_num_c1 = []\n",
    "list_diff = []\n",
    "with tqdm(total=len(big_string)) as pbar:\n",
    "    for item in big_string:\n",
    "        text = \"\"\n",
    "        text = item + \"]\"\n",
    "        text = text.split(\"[\")\n",
    "        fields = text[0]\n",
    "        # print(fields)\n",
    "        if updated_PBC4CIP:\n",
    "            if (len(text) > 1):\n",
    "                class_nums = text[1]\n",
    "                class_nums = class_nums[:-1]\n",
    "                class_nums = class_nums.split()\n",
    "                supports = text[2]\n",
    "                supports = supports[:-1]\n",
    "                supports = supports.split()\n",
    "                list_fields.append(fields.strip())\n",
    "                list_support_c0.append(float(supports[0]))\n",
    "                list_support_c1.append(float(supports[1]))\n",
    "                list_num_c0.append(float(class_nums[0]))\n",
    "                list_num_c1.append(float(class_nums[1]))\n",
    "        else:\n",
    "            if (len(text) > 1):\n",
    "                supports = text[1]\n",
    "                supports = supports[:-1]\n",
    "                supports = supports.split()\n",
    "                list_fields.append(fields.strip())\n",
    "                list_support_c0.append(float(supports[0]))\n",
    "                list_support_c1.append(float(supports[1]))\n",
    "                list_num_c0.append(float(supports[0]*c0_count))\n",
    "                list_num_c1.append(float(supports[1]*c1_count))\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                              fields  support_c0  support_c1  \\\n0  Correo electronico = &#39;imss&#39; AND Entidad federa...         0.0         0.0   \n1  Most_used_UC_word_gyr = &#39;1&#39; AND Entidad federa...         0.0         0.0   \n2  Correo electronico = &#39;imss&#39; AND Entidad federa...         0.0         0.0   \n3  Correo electronico = &#39;imss&#39; AND Most_used_desc...         0.0         0.0   \n4  Most_used_UC_word_gyr = &#39;1&#39; AND Articulo != &#39;4...         0.0         0.0   \n\n   num_c0  num_c1  \n0     0.0     1.0  \n1     0.0     1.0  \n2     0.0     1.0  \n3     0.0     1.0  \n4     0.0     1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fields</th>\n      <th>support_c0</th>\n      <th>support_c1</th>\n      <th>num_c0</th>\n      <th>num_c1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Correo electronico = 'imss' AND Entidad federa...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Most_used_UC_word_gyr = '1' AND Entidad federa...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Correo electronico = 'imss' AND Entidad federa...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Correo electronico = 'imss' AND Most_used_desc...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Most_used_UC_word_gyr = '1' AND Articulo != '4...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['fields', 'support_c0', 'support_c1', 'num_c0', 'num_c1'])\n",
    "df['fields']=list_fields\n",
    "df['support_c0']=list_support_c0\n",
    "df['support_c1']= list_support_c1\n",
    "df['num_c0']= list_num_c0\n",
    "df['num_c1']= list_num_c1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                  fields  support_c0  \\\n19679  Articulo != &#39;43&#39; AND Most_used_UC_word_gyr = &#39;...        0.01   \n19678  Correo electronico != &#39;imss&#39; AND Articulo != &#39;...        0.02   \n\n       support_c1  num_c0   num_c1  s_diff   n_diff     ratio  \n19679        0.42   161.0  34230.0    0.41  34069.0  0.995319  \n19678        0.42   234.0  34223.0    0.40  33989.0  0.993209  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fields</th>\n      <th>support_c0</th>\n      <th>support_c1</th>\n      <th>num_c0</th>\n      <th>num_c1</th>\n      <th>s_diff</th>\n      <th>n_diff</th>\n      <th>ratio</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19679</th>\n      <td>Articulo != '43' AND Most_used_UC_word_gyr = '...</td>\n      <td>0.01</td>\n      <td>0.42</td>\n      <td>161.0</td>\n      <td>34230.0</td>\n      <td>0.41</td>\n      <td>34069.0</td>\n      <td>0.995319</td>\n    </tr>\n    <tr>\n      <th>19678</th>\n      <td>Correo electronico != 'imss' AND Articulo != '...</td>\n      <td>0.02</td>\n      <td>0.42</td>\n      <td>234.0</td>\n      <td>34223.0</td>\n      <td>0.40</td>\n      <td>33989.0</td>\n      <td>0.993209</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "df['s_diff'] = df.support_c1 - df.support_c0\n",
    "df['n_diff'] = df.num_c1 - df.num_c0\n",
    "df['ratio'] = df.num_c1/(df.num_c0 + df.num_c1)\n",
    "\n",
    "df = df[df.s_diff > min_support_diff]\n",
    "df = df[df.n_diff > min_count_diff]\n",
    "df = df[df.ratio > min_ratio]\n",
    "\n",
    "df = df.sort_values(by=['s_diff'], ascending=False)\n",
    "df = df[:max_patterns]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{filename}.csv\", index=False)\n",
    "jvm.stop()"
   ]
  }
 ]
}